{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Name: Arpit Aggarwal</b> <br>\n",
    "<b>UID: 116747189</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header files\n",
    "import numpy as np\n",
    "import torch\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using hw2.ipynb load_data() function. The load_data() function loads data from the training and testing files. Next step, is to flatten the image so that they can be fed as an input to the neural network. Lastly, the training and testing data is normalized between 0 and 1 which will be used for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (209, 12288)\n",
      "test_x's shape: (50, 12288)\n"
     ]
    }
   ],
   "source": [
    "def load_data(train_file, test_file):\n",
    "    # Load the training data\n",
    "    train_dataset = h5py.File(train_file, 'r')\n",
    "    \n",
    "    # Separate features(x) and labels(y) for training set\n",
    "    train_set_x_orig = np.array(train_dataset['train_set_x'])\n",
    "    train_set_y_orig = np.array(train_dataset['train_set_y'])\n",
    "\n",
    "    # Load the test data\n",
    "    test_dataset = h5py.File(test_file, 'r')\n",
    "    \n",
    "    # Separate features(x) and labels(y) for training set\n",
    "    test_set_x_orig = np.array(test_dataset['test_set_x'])\n",
    "    test_set_y_orig = np.array(test_dataset['test_set_y'])\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((test_set_y_orig.shape[0]))\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "# training and testing files\n",
    "train_file=\"data/train_catvnoncat.h5\"\n",
    "test_file=\"data/test_catvnoncat.h5\"\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data(train_file, test_file) \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1)\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1)\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten / 255.\n",
    "test_x = test_x_flatten / 255.\n",
    "\n",
    "# print data length\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convert dataset to Tensor form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataset to Tensor form so that it can be fed into the PyTorch neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torch.from_numpy() to get the tensor form of the numpy array\n",
    "train_x = torch.from_numpy(train_x).float().to(device)\n",
    "train_y = torch.from_numpy(train_y).to(device)\n",
    "train_y = torch.LongTensor(train_y).to(device)\n",
    "test_x = torch.from_numpy(test_x).float().to(device)\n",
    "test_y = torch.from_numpy(test_y).to(device)\n",
    "test_y = torch.LongTensor(test_y).to(device)\n",
    "train_x.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Device Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device configuration using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyper-parameters of the two-layer neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_hidden_neurons = 16\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model-Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-architecture is defined using pytorch Net class. The __init__ function is where we define the architecture of the neural network, i.e in this it is two layers. The forward function is where the forward pass step of the neural network takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=12288, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# neural network class\n",
    "class Net(torch.nn.Module):\n",
    "    # init function\n",
    "    def __init__(self, num_input_neurons, num_hidden_neurons, num_output_neurons):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(num_input_neurons, num_hidden_neurons)\n",
    "        self.fc2 = torch.nn.Linear(num_hidden_neurons, num_output_neurons)\n",
    "        \n",
    "    # forward pass step of the neural network\n",
    "    def forward(self, input):\n",
    "        input = torch.nn.functional.sigmoid(self.fc2(torch.nn.functional.relu(self.fc1(input))))\n",
    "        return input\n",
    "    \n",
    "# get the neural net object\n",
    "net = Net(12288, num_hidden_neurons, 1).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Cross-entropy loss as we are doing image classification (cat vs non-cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to define the optimizer we will be using for training the neural net. We will use gradient descent as out optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be training the neural network to get the optimal set of weights and biases required for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arpitdec5/.local/lib/python2.7/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 100: 0.6733\n",
      "Loss after iteration 200: 0.6733\n",
      "Loss after iteration 300: 0.6733\n",
      "Loss after iteration 400: 0.6733\n",
      "Loss after iteration 500: 0.6733\n",
      "Loss after iteration 600: 0.6733\n",
      "Loss after iteration 700: 0.6733\n",
      "Loss after iteration 800: 0.6733\n",
      "Loss after iteration 900: 0.6733\n",
      "Loss after iteration 1000: 0.6733\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward step\n",
    "    output = net(train_x)\n",
    "    pred_output = []\n",
    "    for index in range(0, output.shape[0]):\n",
    "        class0 = float(1.0 - output[index][0])\n",
    "        class1 = float(output[index][0])\n",
    "        pred_output.append(np.array([class0, class1]))\n",
    "    pred_output = torch.from_numpy(np.array(pred_output)).to(device)\n",
    "    \n",
    "    # find loss\n",
    "    loss = criterion(pred_output, train_y)\n",
    "    loss = torch.tensor(loss.data, requires_grad=True).to(device)\n",
    "    \n",
    "    # backpropagation step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if((epoch + 1)%100 == 0):\n",
    "        print('Loss after iteration {}: {:.4f}' .format(epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
